{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "humanitarian-library",
      "metadata": {
        "id": "humanitarian-library",
        "outputId": "c3bc9df8-e1cb-41e7-fde4-fe2577389e45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PIL 라이브러리 import 완료!\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import os, glob\n",
        "\n",
        "print(\"PIL 라이브러리 import 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "narrative-router",
      "metadata": {
        "id": "narrative-router",
        "outputId": "10bf5b83-3b69-43cd-bfa5-39574de5ef93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "344  images to be resized.\n",
            "344  images resized.\n",
            "가위 이미지 resize 완료!\n"
          ]
        }
      ],
      "source": [
        "def resize_images(img_path):\n",
        "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
        "    \n",
        "\tprint(len(images), \" images to be resized.\")\n",
        "\n",
        "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
        "\ttarget_size=(28,28)\n",
        "\tfor img in images:\n",
        "\t\told_img=Image.open(img)\n",
        "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
        "\t\tnew_img.save(img, \"JPEG\")\n",
        "    \n",
        "\tprint(len(images), \" images resized.\")\n",
        "\t\n",
        "#바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
        "resize_images(image_dir_path)\n",
        "\n",
        "print(\"가위 이미지 resize 완료!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "supported-patent",
      "metadata": {
        "id": "supported-patent",
        "outputId": "6167fad0-271c-44f0-c425-5ec35569e5cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "344  images to be resized.\n",
            "344  images resized.\n",
            "바위 이미지 resize 완료!\n"
          ]
        }
      ],
      "source": [
        "def resize_images(img_path):\n",
        "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
        "    \n",
        "\tprint(len(images), \" images to be resized.\")\n",
        "\n",
        "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
        "\ttarget_size=(28,28)\n",
        "\tfor img in images:\n",
        "\t\told_img=Image.open(img)\n",
        "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
        "\t\tnew_img.save(img, \"JPEG\")\n",
        "    \n",
        "\tprint(len(images), \" images resized.\")\n",
        "\t\n",
        "#바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
        "resize_images(image_dir_path)\n",
        "\n",
        "print(\"바위 이미지 resize 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thermal-saturday",
      "metadata": {
        "id": "thermal-saturday",
        "outputId": "89051e72-619e-499b-dcd6-a0e2664132fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "372  images to be resized.\n",
            "372  images resized.\n",
            "보 이미지 resize 완료!\n"
          ]
        }
      ],
      "source": [
        "def resize_images(img_path):\n",
        "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
        "    \n",
        "\tprint(len(images), \" images to be resized.\")\n",
        "\n",
        "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
        "\ttarget_size=(28,28)\n",
        "\tfor img in images:\n",
        "\t\told_img=Image.open(img)\n",
        "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
        "\t\tnew_img.save(img, \"JPEG\")\n",
        "    \n",
        "\tprint(len(images), \" images resized.\")\n",
        "\t\n",
        "#보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
        "resize_images(image_dir_path)\n",
        "\n",
        "print(\"보 이미지 resize 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fresh-contract",
      "metadata": {
        "id": "fresh-contract",
        "outputId": "bfb0d572-d7cb-4095-fa1d-93a8f1c7c155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습데이터(x_train)의 이미지 개수는 1024 입니다.\n",
            "x_train shape: (1024, 28, 28, 3)\n",
            "y_train shape: (1024,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_data(img_path, number_of_data=1024):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
        "    # 가위 : 0, 바위 : 1, 보 : 2\n",
        "    img_size=28\n",
        "    color=3\n",
        "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
        "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
        "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
        "\n",
        "    idx=0\n",
        "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=0   # 가위 : 0\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=1   # 바위 : 1\n",
        "        idx=idx+1  \n",
        "    \n",
        "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=2   # 보 : 2\n",
        "        idx=idx+1\n",
        "        \n",
        "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
        "    return imgs, labels\n",
        "\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
        "(x_train, y_train)=load_data(image_dir_path)\n",
        "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
        "\n",
        "print(\"x_train shape: {}\".format(x_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deluxe-projection",
      "metadata": {
        "id": "deluxe-projection",
        "outputId": "ab241eb2-ae3a-4c1e-a5ee-f6996bd00f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "라벨:  0\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWwElEQVR4nO3dX2xk9XUH8O+54xn/Gdu7692s2cAWSEorbVJlqSxUKaiiioIID4W0FQqVIlqhbh6ClEh5KKIP2UcUNYnyUCFtCsqmSokiEQRtaBuCIqG8IAzZLgsbyh8tsN5dzK7X9tgez9y59/TBAzKLf+c4c8czI37fj7Syd47vnd/cmTPXnnPP7yeqCiL6+Ev6PQAi6g0mO1EkmOxEkWCyE0WCyU4UiaFe3tnE5C7dt/+qYFxgVwY0z41Yy9w2a6VmvNls2ttnWTCWlErmthAxw/X1hhnftXuPGa9UKuFYORwDgFJiv98PG/sGAHFOF9Yzenlxydy2kdrPWalStu/cGlxiPydJyU4Nr4aVeAfGILDHZoUvzr2D2sLClj9RKNlF5DYAPwBQAvCvqvqg9fP79l+Fo995KBgvwUnY+kowltYXzW2XLl0w42+/9aYZr9VqwVh1125z2yyxE+alV1834395x1+b8asPXheMXXfwD8xtq2OjZvxTBw+a8ZFhM4zUyIrH/uMpc9s3Lpwz47uvPmDGW6PhxyajI+a2Y7vsN9hW+Lyzsf3wmBlPjBOAwD55iLHt0b/6Uvg+zb3ad1gC8C8AvgTgEIC7ReRQp/sjop1V5G/2mwC8rqpvqmoTwE8B3NGdYRFRtxVJ9qsBvLPp/2fbt32IiBwRkVkRma0tLRa4OyIqYsc/jVfVY6o6o6ozE87ftkS0c4ok+xyAzZ/eXNO+jYgGUJFkfx7ADSJyvYhUAHwFwJPdGRYRdVvHpTdVbYnIfQD+Bxult0dU9eWujWzQGHVZderoXmehVUrZ2L9TxzdkbkXYpgXq6AA+tpdtec/ZWmPdjJeMYnlSoPSWG9eiFKqzq+pTAOxiKRENhI/p+y4RXYnJThQJJjtRJJjsRJFgshNFgslOFIme9rMXJk5fYZFdO3XTItvm6tTRvfdcpzfa2r9/317clnd+2OAMzb3vItcQZM61D97j8u55vDpuxovU2c39GvMT8MxOFAkmO1EkmOxEkWCyE0WCyU4UCSY7USR6XHpTCKzy2WCW1tztnX1nXh0ncZ4GZ1rj3HjPzpz6VibOfRdtcTXuXp3pnN3ylxPPjdF523q811PdaXEV48CVirS4GiVFntmJIsFkJ4oEk50oEkx2okgw2YkiwWQnigSTnSgSA9XiatUe3W0L1tG9JXyt6ZzFmerZmt53O9uLU4fPjRbY3JkL2qrRA0DunA6yIi2uXrxAHR2wa87eqsjetRPeFSET1aq9+x2qsydscSUiJjtRJJjsRJFgshNFgslOFAkmO1EkmOxEkRioOvtO8urwbq3b2N7ry87Uqco620vJfk/OzPu279qbStqrJ3u1cmvvbh3dme7ZWwrb6of3znJeL704x21lbc2Ml4zX05AO4JLNInIGQA0br7eWqs4U2R8R7ZxunNn/QlUvdmE/RLSD+Dc7USSKJrsC+KWIvCAiR7b6ARE5IiKzIjJbW1oqeHdE1Kmiv8bfrKpzIrIfwNMi8jtVfXbzD6jqMQDHAOD6P/yjAq0uRFREoTO7qs61v84DeBzATd0YFBF1X8fJLiJVEZl4/3sAtwI41a2BEVF3Ffk1fhrA4+2a3xCAf1fV/y4yGK9uatu5OecBu7YpTv+xasuM507N1ts/jJ51b2lidZaD9vq+vaNubV5kueft3Lc5b3yh15p/jcDY2JgZt+rs3pLN5nLPRj97x8muqm8C+Fyn2xNRb7H0RhQJJjtRJJjsRJFgshNFgslOFInetrhq8ZJHWLH3rcJTUe/gffdzbEUVKqYWXLJ5J7lLNtfrZtx6te5UiyvP7ESRYLITRYLJThQJJjtRJJjsRJFgshNFgslOFImBmkraW9q41Qq3iqZp2vG2AJBl1oTMtsTrQHWuLUgb6/b2uT32VtYMB51j6t13auwaAEZG7Lh1VL3nzHs9eM/ZcKUSDpbL5rarq6tmfHxylxn3pppOrNWknRp+4q43HdqOiKLAZCeKBJOdKBJMdqJIMNmJIsFkJ4oEk50oEj2tsyvs2qlXm9xZdk3XqpVLbtfRh52arjhLOos3abJxDcFwxb4IYNfkhBlP63YtOxuy97/cagRjjUY4BgClkr3vvGWPbXl5ORgbdmrZw1WjRg8gS+1rH9Rbpttoxlfn+U6ssRuvU57ZiSLBZCeKBJOdKBJMdqJIMNmJIsFkJ4oEk50oEj3vZ8+MEmLJmWW8ZWybF52P3qmVJ1btU+16b+I8riy1683N+poZr5TCT+N758+a2444Nd1SOmnG68v2+SKZsK8xsEyMVe19Dw+b8Xoz3C9f8eYvsF6oAOordr/7SGXUjFvXlKg7276xrbGpe2YXkUdEZF5ETm26bUpEnhaR19pf93j7IaL+2s6v8T8CcNsVt90P4BlVvQHAM+3/E9EAc5NdVZ8FsHDFzXcAON7+/jiAO7s7LCLqtk4/oJtW1fPt7y8AmA79oIgcEZFZEZmtLS91eHdEVFThT+N1o0Mk+LGAqh5T1RlVnZlwJukjop3TabK/KyIHAKD9db57QyKindBpsj8J4J729/cAeKI7wyGineLW2UXkUQC3ANgnImcBfBvAgwB+JiL3AngLwF3buTNVIDfq2V510eop9+Zm9+JF1kj33jHzlj0/+pDTxp+n9tzuZQn3pP/2+efMbS/s/4QZv/3WL5rx2qXLZnx87JPBWLNuP668ZB/ZMWteeACjxjMz5E/2b4bThv2cjpW9OrsRK3TNSHhbN9lV9e5A6AudDoeIeo+XyxJFgslOFAkmO1EkmOxEkWCyE0Wix1NJK9I83FpYclpFsyxcVvCW7/WW//VYVaChsvOe6Sy5PD5mt2omam9fHQm3kZ4++Vtz28v79prxv//bvzHjrXrNjFvTbHtLNq/W7Xh5ctyMJ+VwaU6c6pY3Pfio016r3uvNmEo6MWIAkBhh63HxzE4UCSY7USSY7ESRYLITRYLJThQJJjtRJJjsRJHobZ1dgdSYD7qV2fXkLG2G953adfaWsawxAOROLdsyJPZ7ZsuZKnrIKpwCWFuxp/OqLV4Kxi6cfdu+78xuM129HN43ADRqV05P+GGyJzzx8K4Je5rqdHXFjjt1ejWm2M6d10Mjt49LtWovde0tJ23NVC1Os7eaU0lzyWai6DHZiSLBZCeKBJOdKBJMdqJIMNmJIsFkJ4pEj+vsOZrNcK1cMrtumq6Ha59qxACY9wsAeWrXXRMNF0YTpznamxrYW7L54oXzZnx+LhxfqdlTPWf77FV6/usXT5pxbznp0fMXw/ftzEEwOWnX4Vec6zKsp8WbOny9YT8nw8P2VNFD6k1VbYScfnZ7IuowntmJIsFkJ4oEk50oEkx2okgw2YkiwWQnigSTnSgSPe9nN/vKnaWNrf5ldXqbvd5nr+YLdD7v/NiIvbSwOvPKLy4umvG5d852vO+hkl2z/cV/2nX2cafevHjidDD2x5/5rLnt9PXXmfHUeb2EZ9MHymUrCjRS+/n25p33WHV+ceroXjzEPbOLyCMiMi8ipzbddlRE5kTkRPvf7R3dOxH1zHZ+jf8RgNu2uP37qnq4/e+p7g6LiLrNTXZVfRaAPfcQEQ28Ih/Q3SciJ9u/5gcnGhORIyIyKyKzqyvLBe6OiIroNNkfAvBpAIcBnAfw3dAPquoxVZ1R1ZnquN3YQEQ7p6NkV9V3VTVT1RzADwHc1N1hEVG3dZTsInJg03+/DOBU6GeJaDC4dXYReRTALQD2ichZAN8GcIuIHMZGV+4ZAF/b1p1lKaZWwv3NtRV7nvC1Wnj+9EycOnliP9SkbK/13crC/c1eDX/vbrsWvfcz15nxy/PnzHilGj5uh26w+9WrQ+HnAwDKFft8MFqx6/gHy+GC9PIJu4ijJ+3nbDKxa+XVqfDa80POnPXl1C6kV6f2mXGU7fXbJ/aEt8+ddQhW6vVwcK0WDLnJrqp3b3Hzw952RDRYeLksUSSY7ESRYLITRYLJThQJJjtRJHra4pplGRaXwuUzddpIK5Vwq2ie2NuuN41yBYDUmc5ZES4xlZw20X1TU2Z8zVn2eMGZirqxFn5sLafFNRuy3++rw3YJqeycL3535tVgbP6S/bg1sffd9MqpRvutV3prOFNBlyftkuahz91oxhdWwlNwW8uaA/ZxaRltvzyzE0WCyU4UCSY7USSY7ESRYLITRYLJThQJJjtRJHpaZ4cIEqOu600NXE/D9WSvTu7FM+e+h4xuyrKz/G99zW7d1aZdCx+r2K2cmArOCoYRp1ZdEbumO1Jy2kzHx8z4ejPcepw6x23v9LQZH3faTBtGq2gybLc015wlvOvOzOIrXrt2KzxFW71hvxYrwyPBmDVVO8/sRJFgshNFgslOFAkmO1EkmOxEkWCyE0WCyU4UiR7X2YG8FO7NbjSb5uZr66vBWKtlbztktydDnDV4U6NnfOGiXXS99sB+M97M7JquccgAABUJPzjJnGsX1sJ91QCw7ixl3Vq35wmY3h2ezrnWsJ+zvdNXmfF9n7zGjK+l4bGrs9T0WG4/p0tr9nUbq861E5VyOPUyZ0XmVm48LmM7ntmJIsFkJ4oEk50oEkx2okgw2YkiwWQnigSTnSgSPa2zt7IWLtcudby9tUJvpWQX0nOnXz1thGv4gL1cdF633zNLB+y+69y4fgAA1pfDvc8AsG6MreTUi7Vp14tHnXnjd1Xt+ddHxsN94813z5vbzi9cNuO1zKmF19eDsWTM7mfXofAaBQCw7pwnR6oTZnz3rt3B2HDTfq1eWlg04yHumV1EDorIr0XkFRF5WUS+0b59SkSeFpHX2l/DMygQUd9t59f4FoBvqeohAH8G4OsicgjA/QCeUdUbADzT/j8RDSg32VX1vKq+2P6+BuA0gKsB3AHgePvHjgO4c4fGSERd8Ht9QCci1wG4EcBzAKZV9f0/ui4A2HLCMBE5IiKzIjJbr9vXYRPRztl2sovIOIDHAHxTVT/0iZGqKgLX4KvqMVWdUdWZ0VF7ckIi2jnbSnYRKWMj0X+iqj9v3/yuiBxoxw8AmN+ZIRJRN7ilNxERAA8DOK2q39sUehLAPQAebH99wtuXQpFKuD2v4vWhGl2Dy7VFc9O15XB5CgDqS/b2w8aR2j1hl9YWztslpnVn7Omq/efPsLF08UjF7pfMnZJldTQ8bTEA7HaWLi5Xq8HYmLNtpWq3oZacsqB1XNKSPT13M7f7ipOKfdzWnKnLxxLjeXGm2G6k4ZKiGst7b6fO/nkAXwXwkoicaN/2ADaS/Gcici+AtwDctY19EVGfuMmuqr8BEHqr+UJ3h0NEO4WXyxJFgslOFAkmO1EkmOxEkWCyE0Wipy2ukghKI+H6ZtOpTS7VFsKxxXBsY+fh2iQAVIylpAFgfCTc8li1ivAAVhfttt7mit3i6k3XXLamJc7tx1VbXDTjq0v29olzvhifDtd9U2eK7GFjyWUASCp2nX1iPPyc1Zypni8v2W3FQ2W7zp6mTvttLbz/9YadB41WOJ4jfL88sxNFgslOFAkmO1EkmOxEkWCyE0WCyU4UCSY7USR6WmfPNcdqoxaM152+7aXVcE/6kNO3vX/vlrNmfaBsLIMLAOtGHX/hwgVz2zGnhu/V0RvOcUkq4WsXSsN2P/pIxe4Zn5y0p4o+eM21Zrw+Gq6FjzpLVWfO/AYNZznqchJ+bLkxrwIAqLNs8pgzVfTiyooZX1kL58Haur2Udad4ZieKBJOdKBJMdqJIMNmJIsFkJ4oEk50oEkx2okj0tM6eJAlGJ8JL5U7usWu6u3eFt7Xq4AAgLbum21yza9lZw1j+N7XrveMTU2Z8/7hdsz33zttmfPnyYkcxAGi17L7rmlPjvzD/nhm/5vCfBGMjxpzyG3F7WeXM6XdfbYTr1evOEt6jE/ZrMXWuyxiq2KmVBydsBqrOfPmWkrEOAM/sRJFgshNFgslOFAkmO1EkmOxEkWCyE0WCyU4Uie2sz34QwI8BTANQAMdU9QcichTAPwB4v9D6gKo+Ze0r0xwrjfAc6aN5eJ5vAKithPvZ58/NmdvW37toxqVu15PHjfW094/bNdmG09s8MmrXm/dM7jHjB/YfCMZGR+2ardc7XS7b65irUS8GgGQivAb7kNGHDwAqdj975sw7n8H4gcTed+KsW4/EPk9a66QDsEbm9tKLvXUwsp2LaloAvqWqL4rIBIAXROTpduz7qvrP29gHEfXZdtZnPw/gfPv7moicBnD1Tg+MiLrr9/qbXUSuA3AjgOfaN90nIidF5BER2fJ3TRE5IiKzIjK7vmZPv0REO2fbyS4i4wAeA/BNVV0G8BCATwM4jI0z/3e32k5Vj6nqjKrOjIx1fs0vERWzrWQXkTI2Ev0nqvpzAFDVd1U1U9UcwA8B3LRzwySiotxkFxEB8DCA06r6vU23b/4I+MsATnV/eETULdv5NP7zAL4K4CUROdG+7QEAd4vIYWx81n8GwNe8HaVpirn58LTLU860xY21cNlu3tgvAFx44w17cCt2q+e1U2PB2N6RcAzwp4JeddpME6fMM22U3vbu329uW1uxx+aVgZDYL6HlofBjM0tjANLMPi7Nlt1mmuXh/TtVO5dXWvMemzkCZ1MzbAS382n8b4Ati6lmTZ2IBguvoCOKBJOdKBJMdqJIMNmJIsFkJ4oEk50oEj2dSrqZppg7dy4YT5z6Ylntuqul0bC3zewuVKyPhK/rV2da4lI5vGwxANTrds9A1rIPTL0ZblPNnUL5ulerdqZrHhmz25I1CR+b3Jneu5HaY2t604MbtfDceVyZ2vvOjRr+xg7s11vuXb9gSMw8CI+LZ3aiSDDZiSLBZCeKBJOdKBJMdqJIMNmJIsFkJ4qEeH25Xb0zkfcAvLXppn0A7Dme+2dQxzao4wI4tk51c2zXquontgr0NNk/cucis6o607cBGAZ1bIM6LoBj61SvxsZf44kiwWQnikS/k/1Yn+/fMqhjG9RxARxbp3oytr7+zU5EvdPvMzsR9QiTnSgSfUl2EblNRF4VkddF5P5+jCFERM6IyEsickJEZvs8lkdEZF5ETm26bUpEnhaR19pf7fWcezu2oyIy1z52J0Tk9j6N7aCI/FpEXhGRl0XkG+3b+3rsjHH15Lj1/G92ESkB+D8AXwRwFsDzAO5W1Vd6OpAAETkDYEZV+34Bhoj8OYAVAD9W1c+2b/sOgAVVfbD9RrlHVf9xQMZ2FMBKv5fxbq9WdGDzMuMA7gTwd+jjsTPGdRd6cNz6cWa/CcDrqvqmqjYB/BTAHX0Yx8BT1WcBLFxx8x0Ajre/P46NF0vPBcY2EFT1vKq+2P6+BuD9Zcb7euyMcfVEP5L9agDvbPr/WQzWeu8K4Jci8oKIHOn3YLYwrarn299fADDdz8FswV3Gu5euWGZ8YI5dJ8ufF8UP6D7qZlX9UwBfAvD19q+rA0k3/gYbpNrptpbx7pUtlhn/QD+PXafLnxfVj2SfA3Bw0/+vad82EFR1rv11HsDjGLylqN99fwXd9tf5Po/nA4O0jPdWy4xjAI5dP5c/70eyPw/gBhG5XkQqAL4C4Mk+jOMjRKTa/uAEIlIFcCsGbynqJwHc0/7+HgBP9HEsHzIoy3iHlhlHn49d35c/V9We/wNwOzY+kX8DwD/1YwyBcX0KwP+2/73c77EBeBQbv9al2Phs414AewE8A+A1AL8CMDVAY/s3AC8BOImNxDrQp7HdjI1f0U8CONH+d3u/j50xrp4cN14uSxQJfkBHFAkmO1EkmOxEkWCyE0WCyU4UCSY7USSY7ESR+H9Xgbxy0J4brAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[99])\n",
        "print('라벨: ', y_train[99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "organized-empty",
      "metadata": {
        "id": "organized-empty",
        "outputId": "300ba4e2-2a16-4c98-bd4f-f8492c69c697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model에 추가된 Layer 개수:  7\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                25632     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 30,819\n",
            "Trainable params: 30,819\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "model=keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D((2,2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(32, activation='relu'))\n",
        "model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "established-person",
      "metadata": {
        "id": "established-person",
        "outputId": "86ed6863-6740-471c-aba4-8d0c697fab0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before Reshape - x_train_norm shape: (1024, 28, 28, 3)\n",
            "After Reshape - x_train_reshaped shape: (1024, 28, 28, 3)\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 3s 3ms/step - loss: 1.0641 - accuracy: 0.4248\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7892 - accuracy: 0.7268\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.8158\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8500\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8881\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.9209\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9206\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9555\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1351 - accuracy: 0.9567\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9728\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e506512d0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
        "# print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
        "\n",
        "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
        "# x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)\n",
        "\n",
        "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
        "# print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train_reshaped, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "entitled-springer",
      "metadata": {
        "id": "entitled-springer",
        "outputId": "a251ae1a-bd31-46c0-999a-b1e14d4ea440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습데이터(x_train)의 이미지 개수는 200 입니다.\n",
            "x_train shape: (1024, 28, 28, 3)\n",
            "y_train shape: (1024,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_data(img_path, number_of_data=1024):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
        "    # 가위 : 0, 바위 : 1, 보 : 2\n",
        "    img_size=28\n",
        "    color=3\n",
        "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
        "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
        "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
        "\n",
        "    idx=0\n",
        "    for file in glob.iglob(img_path+'/test/scissor_test/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=0   # 가위 : 0\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'/test/rock_test/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=1   # 바위 : 1\n",
        "        idx=idx+1  \n",
        "    \n",
        "    for file in glob.iglob(img_path+'/paper_test/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=2   # 보 : 2\n",
        "        idx=idx+1\n",
        "        \n",
        "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
        "    return imgs, labels\n",
        "\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
        "(x_test, y_test)=load_data(image_dir_path)\n",
        "x_train = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
        "\n",
        "print(\"x_train shape: {}\".format(x_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deluxe-holmes",
      "metadata": {
        "id": "deluxe-holmes",
        "outputId": "43273c39-f28b-4627-e3f9-52e69485a560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100  images to be resized.\n",
            "100  images resized.\n",
            "가위 이미지 resize 완료!\n",
            "100  images to be resized.\n",
            "100  images resized.\n",
            "바위 이미지 resize 완료!\n",
            "100  images to be resized.\n",
            "100  images resized.\n",
            "보 이미지 resize 완료!\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                25632     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 31,050\n",
            "Trainable params: 31,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 1s 3ms/step - loss: 1.6432 - accuracy: 0.3019\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0325 - accuracy: 0.4644\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7544 - accuracy: 0.7189\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7254\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7869\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.8371\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8456\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 0.8837\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2701 - accuracy: 0.9150\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.9244\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5ed92f9650>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def resize_images(img_path):\n",
        "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
        "    \n",
        "\tprint(len(images), \" images to be resized.\")\n",
        "\n",
        "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
        "\ttarget_size=(28,28)\n",
        "\tfor img in images:\n",
        "\t\told_img=Image.open(img)\n",
        "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
        "\t\tnew_img.save(img, \"JPEG\")\n",
        "    \n",
        "\tprint(len(images), \" images resized.\")\n",
        "\t\n",
        "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor_test\"\n",
        "resize_images(image_dir_path)\n",
        "\n",
        "print(\"가위 이미지 resize 완료!\")\n",
        "\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock_test\"\n",
        "resize_images(image_dir_path)\n",
        "\n",
        "print(\"바위 이미지 resize 완료!\")\n",
        "\n",
        "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper_test\"\n",
        "resize_images(image_dir_path)\n",
        "\n",
        "print(\"보 이미지 resize 완료!\")\n",
        "\n",
        "\n",
        "# 바꿔 볼 수 있는 하이퍼파라미터들\n",
        "n_channel_1=16\n",
        "n_channel_2=32\n",
        "n_dense=32\n",
        "n_train_epoch=10\n",
        "\n",
        "model=keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D((2,2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "included-nurse",
      "metadata": {
        "id": "included-nurse"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "E01_rock_scissor_paper.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}